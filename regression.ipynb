{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import learning_curve, validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./databases/train.csv\")\n",
    "test_df =  pd.read_csv(\"./databases/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>date</th>\n",
       "      <th>Lagging_Current_Reactive.Power_kVarh</th>\n",
       "      <th>Leading_Current_Reactive_Power_kVarh</th>\n",
       "      <th>CO2(tCO2)</th>\n",
       "      <th>Lagging_Current_Power_Factor</th>\n",
       "      <th>Leading_Current_Power_Factor</th>\n",
       "      <th>NSM</th>\n",
       "      <th>WeekStatus</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Load_Type</th>\n",
       "      <th>Usage_kWh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2018 0:15</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>73.21</td>\n",
       "      <td>100.0</td>\n",
       "      <td>900</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/1/2018 0:30</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>66.77</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1800</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/1/2018 0:45</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.28</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2700</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/1/2018 1:00</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68.09</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3600</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1/1/2018 1:15</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64.72</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4500</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Light_Load</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27994</th>\n",
       "      <td>27995</td>\n",
       "      <td>19/10/2018 14:45</td>\n",
       "      <td>32.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>85.75</td>\n",
       "      <td>100.0</td>\n",
       "      <td>53100</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Maximum_Load</td>\n",
       "      <td>54.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>19/10/2018 15:00</td>\n",
       "      <td>35.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>84.76</td>\n",
       "      <td>100.0</td>\n",
       "      <td>54000</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Maximum_Load</td>\n",
       "      <td>56.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>19/10/2018 15:15</td>\n",
       "      <td>30.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>89.63</td>\n",
       "      <td>100.0</td>\n",
       "      <td>54900</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Maximum_Load</td>\n",
       "      <td>62.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>19/10/2018 15:30</td>\n",
       "      <td>58.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>83.89</td>\n",
       "      <td>100.0</td>\n",
       "      <td>55800</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Maximum_Load</td>\n",
       "      <td>89.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>19/10/2018 15:45</td>\n",
       "      <td>40.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>83.51</td>\n",
       "      <td>100.0</td>\n",
       "      <td>56700</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Maximum_Load</td>\n",
       "      <td>61.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27999 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id              date  Lagging_Current_Reactive.Power_kVarh  \\\n",
       "0          1     1/1/2018 0:15                                  2.95   \n",
       "1          2     1/1/2018 0:30                                  4.46   \n",
       "2          3     1/1/2018 0:45                                  3.28   \n",
       "3          4     1/1/2018 1:00                                  3.56   \n",
       "4          5     1/1/2018 1:15                                  4.50   \n",
       "...      ...               ...                                   ...   \n",
       "27994  27995  19/10/2018 14:45                                 32.62   \n",
       "27995  27996  19/10/2018 15:00                                 35.46   \n",
       "27996  27997  19/10/2018 15:15                                 30.92   \n",
       "27997  27998  19/10/2018 15:30                                 58.18   \n",
       "27998  27999  19/10/2018 15:45                                 40.46   \n",
       "\n",
       "       Leading_Current_Reactive_Power_kVarh  CO2(tCO2)  \\\n",
       "0                                       0.0       0.00   \n",
       "1                                       0.0       0.00   \n",
       "2                                       0.0       0.00   \n",
       "3                                       0.0       0.00   \n",
       "4                                       0.0       0.00   \n",
       "...                                     ...        ...   \n",
       "27994                                   0.0       0.02   \n",
       "27995                                   0.0       0.03   \n",
       "27996                                   0.0       0.03   \n",
       "27997                                   0.0       0.04   \n",
       "27998                                   0.0       0.03   \n",
       "\n",
       "       Lagging_Current_Power_Factor  Leading_Current_Power_Factor    NSM  \\\n",
       "0                             73.21                         100.0    900   \n",
       "1                             66.77                         100.0   1800   \n",
       "2                             70.28                         100.0   2700   \n",
       "3                             68.09                         100.0   3600   \n",
       "4                             64.72                         100.0   4500   \n",
       "...                             ...                           ...    ...   \n",
       "27994                         85.75                         100.0  53100   \n",
       "27995                         84.76                         100.0  54000   \n",
       "27996                         89.63                         100.0  54900   \n",
       "27997                         83.89                         100.0  55800   \n",
       "27998                         83.51                         100.0  56700   \n",
       "\n",
       "      WeekStatus Day_of_week     Load_Type  Usage_kWh  \n",
       "0        Weekday      Monday    Light_Load       3.17  \n",
       "1        Weekday      Monday    Light_Load       4.00  \n",
       "2        Weekday      Monday    Light_Load       3.24  \n",
       "3        Weekday      Monday    Light_Load       3.31  \n",
       "4        Weekday      Monday    Light_Load       3.82  \n",
       "...          ...         ...           ...        ...  \n",
       "27994    Weekday      Friday  Maximum_Load      54.36  \n",
       "27995    Weekday      Friday  Maximum_Load      56.63  \n",
       "27996    Weekday      Friday  Maximum_Load      62.50  \n",
       "27997    Weekday      Friday  Maximum_Load      89.68  \n",
       "27998    Weekday      Friday  Maximum_Load      61.42  \n",
       "\n",
       "[27999 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_null = train_df.isnull()\n",
    "print(train_df_null.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_null = test_df.isnull()\n",
    "print(test_df_null.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_mean = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "train_df['Leading_Current_Reactive_Power_kVarh'] = imputer_mean.fit_transform(train_df[['Leading_Current_Reactive_Power_kVarh']])\n",
    "train_df['Leading_Current_Power_Factor'] = imputer_mean.fit_transform(train_df[['Leading_Current_Power_Factor']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekStatus(day):\n",
    "    if day in ['Saturday','Sunday']:\n",
    "        return 'Weekend'\n",
    "    else:\n",
    "        return 'Weekday'\n",
    "    \n",
    "train_df ['WeekStatus'] = train_df['Day_of_week'].apply(weekStatus)   \n",
    "test_df ['WeekStatus'] = test_df['Day_of_week'].apply(weekStatus)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['date'] = pd.to_datetime(train_df['date'], format='%d/%m/%Y %H:%M')\n",
    "test_df['date'] = pd.to_datetime(test_df['date'], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "train_df['Day_of_week'] = train_df['date'].dt.day_name()\n",
    "test_df['Day_of_week'] = test_df['date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_null = train_df.isnull()\n",
    "print(train_df_null.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_null = test_df.isnull()\n",
    "print(test_df_null.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['WeekStatus', 'Day_of_week', 'Load_Type']\n",
    "label_encoder = LabelEncoder()\n",
    "train_df_label_encoder = train_df.copy()\n",
    "test_df_label_encoder = test_df.copy()\n",
    "\n",
    "for feature in categorical_features:\n",
    "    train_df_label_encoder[feature] = label_encoder.fit_transform(train_df_label_encoder[feature])\n",
    "    test_df_label_encoder[feature] = label_encoder.transform(test_df_label_encoder[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_label_encoder['month'] = train_df_label_encoder['date'].dt.month\n",
    "train_df_label_encoder['day'] = train_df_label_encoder['date'].dt.day\n",
    "train_df_label_encoder['hour'] = train_df_label_encoder['date'].dt.hour\n",
    "train_df_label_encoder['minute'] = train_df_label_encoder['date'].dt.minute\n",
    "train_df_label_encoder = train_df_label_encoder.drop(columns=['date'])\n",
    "train_df_label_encoder = train_df_label_encoder.drop(columns=['Id'])\n",
    "train_df_label_encoder = train_df_label_encoder.drop(columns=['Day_of_week'])\n",
    "\n",
    "\n",
    "test_df_label_encoder['month'] = test_df_label_encoder['date'].dt.month\n",
    "test_df_label_encoder['day'] = test_df_label_encoder['date'].dt.day\n",
    "test_df_label_encoder['hour'] = test_df_label_encoder['date'].dt.hour\n",
    "test_df_label_encoder['minute'] = test_df_label_encoder['date'].dt.minute\n",
    "test_df_label_encoder = test_df_label_encoder.drop(columns=['date'])\n",
    "test_df_label_encoder = test_df_label_encoder.drop(columns=['Id'])\n",
    "test_df_label_encoder = test_df_label_encoder.drop(columns=['Day_of_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_without_target = ['Lagging_Current_Reactive.Power_kVarh', 'Leading_Current_Reactive_Power_kVarh', \n",
    "                           'CO2(tCO2)', 'Lagging_Current_Power_Factor','Leading_Current_Power_Factor', \n",
    "                           'NSM', 'WeekStatus', 'Load_Type','month', 'day','hour', 'minute']\n",
    "\n",
    "train_df_scaled = train_df_label_encoder.copy()\n",
    "test_df_scaled = test_df_label_encoder.copy()\n",
    "\n",
    "train_df_scaled[features_without_target] = pd.DataFrame(scaler.fit_transform(train_df_label_encoder[features_without_target]))\n",
    "test_df_scaled[features_without_target] = pd.DataFrame(scaler.transform(test_df_label_encoder[features_without_target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores_train = np.abs(stats.zscore(train_df_scaled[features_without_target]))\n",
    "outliers = z_scores_train > 3\n",
    "print(outliers.sum())\n",
    "outlier_indices = np.where(z_scores_train > 3)\n",
    "outlier_indices = np.unique(outlier_indices[0])\n",
    "train_df_scaled = train_df_scaled.drop(index=outlier_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "\n",
    "label = 'Usage_kWh'\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform KFold cross-validation\n",
    "validation_rmse = []\n",
    "for fold, (train_index, valid_index) in enumerate(kf.split(train_df_scaled), 1):\n",
    "    print(f\"Fold {fold}\")\n",
    "    \n",
    "    # Split the data into training and validation sets for this fold\n",
    "    X_train, X_valid = train_df_scaled.iloc[train_index][features_without_target], train_df_scaled.iloc[valid_index][features_without_target]\n",
    "    y_train, y_valid = train_df_scaled.iloc[train_index][label], train_df_scaled.iloc[valid_index][label]\n",
    "\n",
    "    # Initialize and train Linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_pred_valid = model.predict(X_valid)\n",
    "    \n",
    "    # Calculate RMSE (Root Mean Squared Error)\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred_valid))\n",
    "    print(f\"Validation RMSE: {rmse}\")\n",
    "    validation_rmse.append(rmse)\n",
    "\n",
    "    # Make predictions on the test set (assuming 'test_df_with_id' is your test dataset)\n",
    "    test_predictions = model.predict(test_df_scaled[features_without_target])\n",
    "    \n",
    "    # Create a DataFrame for predictions with 'Id' column from 'test_df_with_id'\n",
    "    submission_df = pd.DataFrame({'Id': test_df['Id'], 'Usage_kWh_Predicted': test_predictions})\n",
    "    \n",
    "    # Save the predictions to a CSV file with IDs\n",
    "    submission_df.to_csv(f'predictions_fold_{fold}.csv', index=False)\n",
    "\n",
    "# Optionally, you can calculate the mean validation RMSE\n",
    "mean_validation_rmse = np.mean(validation_rmse)\n",
    "print(f\"Mean Validation RMSE: {mean_validation_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Usage_kWh'\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform KFold cross-validation\n",
    "validation_rmse = []\n",
    "for fold, (train_index, valid_index) in enumerate(kf.split(train_df_scaled), 1):\n",
    "    print(f\"Fold {fold}\")\n",
    "    \n",
    "    # Split the data into training and validation sets for this fold\n",
    "    X_train, X_valid = train_df_scaled.iloc[train_index][features_without_target], train_df_scaled.iloc[valid_index][features_without_target]\n",
    "    y_train, y_valid = train_df_scaled.iloc[train_index][label], train_df_scaled.iloc[valid_index][label]\n",
    "\n",
    "    # Create a polynomial regression pipeline\n",
    "    model = make_pipeline(PolynomialFeatures(degree=3), LinearRegression())\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_pred_valid = model.predict(X_valid)\n",
    "    \n",
    "    # Calculate RMSE (Root Mean Squared Error)\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred_valid))\n",
    "    print(f\"Validation RMSE: {rmse}\")\n",
    "    validation_rmse.append(rmse)\n",
    "\n",
    "    # Make predictions on the test set (assuming 'test_df_with_id' is your test dataset)\n",
    "    test_predictions = model.predict(test_df_scaled[features_without_target])\n",
    "    \n",
    "    # Create a DataFrame for predictions with 'Id' column from 'test_df_with_id'\n",
    "    submission_df = pd.DataFrame({'Id': test_df['Id'], 'Usage_kWh_Predicted': test_predictions})\n",
    "    \n",
    "    # Save the predictions to a CSV file with IDs\n",
    "    submission_df.to_csv(f'predictions_fold_{fold}.csv', index=False)\n",
    "\n",
    "# Optionally, you can calculate the mean validation RMSE\n",
    "mean_validation_rmse = np.mean(validation_rmse)\n",
    "print(f\"Mean Validation RMSE: {mean_validation_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curves\n",
    "train_sizes, train_scores, valid_scores = learning_curve(model, X_train, y_train, cv=10, scoring='neg_root_mean_squared_error')\n",
    "train_scores_mean = -np.mean(train_scores, axis=1)\n",
    "valid_scores_mean = -np.mean(valid_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_scores_mean, label='Training error')\n",
    "plt.plot(train_sizes, valid_scores_mean, label='Validation error')\n",
    "plt.xlabel('Training set size')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Learning Curves')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Validation Curves\n",
    "degrees = np.arange(1, 10)  # Adjust range as needed\n",
    "train_scores, valid_scores = validation_curve(model, X_train, y_train, param_name='polynomialfeatures__degree', param_range=degrees, cv=10, scoring='neg_root_mean_squared_error')\n",
    "train_scores_mean = -np.mean(train_scores, axis=1)\n",
    "valid_scores_mean = -np.mean(valid_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(degrees, train_scores_mean, label='Training error')\n",
    "plt.plot(degrees, valid_scores_mean, label='Validation error')\n",
    "plt.xlabel('Degree of polynomial features')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Validation Curves')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
